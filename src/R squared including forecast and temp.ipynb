{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-05T02:53:13.683947500Z",
     "start_time": "2025-04-05T02:52:55.477025600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waseem\\AppData\\Local\\Temp\\ipykernel_17264\\1254910683.py:20: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_temperature = pd.read_csv(temperature_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded forecast data: 10906019 rows\n",
      "Loaded demand data: 196513 rows\n",
      "Loaded temperature data: 220326 rows\n",
      "\n",
      "Sample forecast datetime: 2010-01-01 00:00:00\n",
      "Sample demand datetime: 1/01/2010 0:00\n",
      "Sample temperature DATETIME: 1/01/2010 0:00\n",
      "Filtered forecast data for PERIODID 24: 196505 rows\n",
      "Forecast datetime format appears to be: ISO\n",
      "Demand datetime format appears to be: Australian\n",
      "Parsing dates...\n",
      "\n",
      "After parsing:\n",
      "Sample forecast datetime: 2010-01-01 00:00:00\n",
      "Sample demand datetime: 2010-01-01 00:00:00\n",
      "Sample temperature datetime: 2010-01-01 00:00:00\n",
      "Using temperature column: TEMPERATURE\n",
      "Merging forecast with demand data...\n",
      "Merged forecast and demand: 196505 rows\n",
      "Aggregating temperature data by hour...\n",
      "Merging with temperature data...\n",
      "Final merged dataset: 196505 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waseem\\AppData\\Local\\Temp\\ipykernel_17264\\1254910683.py:138: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df_temperature['hour'] = df_temperature['DATETIME'].dt.floor('H')\n",
      "C:\\Users\\waseem\\AppData\\Local\\Temp\\ipykernel_17264\\1254910683.py:145: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  merged_df['hour'] = merged_df['DATETIME'].dt.floor('H')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Forecast Accuracy Metrics for PERIODID 24:\n",
      "Mean Absolute Error (MAE): 169.09 MW\n",
      "Mean Absolute Percentage Error (MAPE): 2.05%\n",
      "Root Mean Square Error (RMSE): 234.87 MW\n",
      "R-squared (R²): 0.9673\n",
      "\n",
      "Analyzing temperature impact on forecast accuracy...\n",
      "Rows with temperature data: 196141 out of 196505 total rows\n",
      "\n",
      "Using specified temperature ranges:\n",
      "  <= 0: 16 samples\n",
      "  0-5: 2710 samples\n",
      "  5-10: 19550 samples\n",
      "  10-15: 42344 samples\n",
      "  15-20: 62603 samples\n",
      "  20-25: 51527 samples\n",
      "  25-30: 14269 samples\n",
      "  30-35: 2568 samples\n",
      "  35-40: 484 samples\n",
      "  > 40: 70 samples\n",
      "\n",
      "Forecast Accuracy by Temperature Range:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\waseem\\AppData\\Local\\Temp\\ipykernel_17264\\1254910683.py:214: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_df_with_temp['TEMP_RANGE'] = pd.cut(\n",
      "C:\\Users\\waseem\\AppData\\Local\\Temp\\ipykernel_17264\\1254910683.py:238: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  accuracy_by_temp = full_df_with_temp.groupby('TEMP_RANGE').agg({\n",
      "C:\\Users\\waseem\\AppData\\Local\\Temp\\ipykernel_17264\\1254910683.py:245: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  r_squared_by_temp = full_df_with_temp.groupby('TEMP_RANGE').apply(calculate_r_squared)\n",
      "C:\\Users\\waseem\\AppData\\Local\\Temp\\ipykernel_17264\\1254910683.py:245: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  r_squared_by_temp = full_df_with_temp.groupby('TEMP_RANGE').apply(calculate_r_squared)\n"
     ]
    },
    {
     "data": {
      "text/plain": "                   MAE      MAPE  Count  R-squared\nTEMP_RANGE                                        \n<= 0        162.318750  2.090544     16   0.960227\n0-5         132.277295  1.653575   2710   0.975757\n5-10        137.099084  1.678702  19550   0.983940\n10-15       160.561842  1.919153  42344   0.977542\n15-20       150.157787  1.936071  62603   0.963830\n20-25       175.763657  2.162140  51527   0.941278\n25-30       261.557903  2.840032  14269   0.930041\n30-35       348.152960  3.455496   2568   0.912743\n35-40       441.745868  3.869580    484   0.810509\n> 40        475.275714  3.866062     70   0.807524",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MAE</th>\n      <th>MAPE</th>\n      <th>Count</th>\n      <th>R-squared</th>\n    </tr>\n    <tr>\n      <th>TEMP_RANGE</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>&lt;= 0</th>\n      <td>162.318750</td>\n      <td>2.090544</td>\n      <td>16</td>\n      <td>0.960227</td>\n    </tr>\n    <tr>\n      <th>0-5</th>\n      <td>132.277295</td>\n      <td>1.653575</td>\n      <td>2710</td>\n      <td>0.975757</td>\n    </tr>\n    <tr>\n      <th>5-10</th>\n      <td>137.099084</td>\n      <td>1.678702</td>\n      <td>19550</td>\n      <td>0.983940</td>\n    </tr>\n    <tr>\n      <th>10-15</th>\n      <td>160.561842</td>\n      <td>1.919153</td>\n      <td>42344</td>\n      <td>0.977542</td>\n    </tr>\n    <tr>\n      <th>15-20</th>\n      <td>150.157787</td>\n      <td>1.936071</td>\n      <td>62603</td>\n      <td>0.963830</td>\n    </tr>\n    <tr>\n      <th>20-25</th>\n      <td>175.763657</td>\n      <td>2.162140</td>\n      <td>51527</td>\n      <td>0.941278</td>\n    </tr>\n    <tr>\n      <th>25-30</th>\n      <td>261.557903</td>\n      <td>2.840032</td>\n      <td>14269</td>\n      <td>0.930041</td>\n    </tr>\n    <tr>\n      <th>30-35</th>\n      <td>348.152960</td>\n      <td>3.455496</td>\n      <td>2568</td>\n      <td>0.912743</td>\n    </tr>\n    <tr>\n      <th>35-40</th>\n      <td>441.745868</td>\n      <td>3.869580</td>\n      <td>484</td>\n      <td>0.810509</td>\n    </tr>\n    <tr>\n      <th>&gt; 40</th>\n      <td>475.275714</td>\n      <td>3.866062</td>\n      <td>70</td>\n      <td>0.807524</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fitting nonlinear model with temperature and forecast as predictors...\n",
      "\n",
      "Nonlinear Model Results (Polynomial Temperature + Forecast):\n",
      "R-squared: 0.9687\n",
      "Coefficients:\n",
      "  Temperature: -25.346849\n",
      "  Temperature²: 0.769912\n",
      "  Forecast: 0.969277\n",
      "  Intercept: 438.465014\n",
      "\n",
      "R-squared Comparison:\n",
      "  Temperature Only (Linear): 0.0222\n",
      "  Temperature Only (Polynomial): 0.0971\n",
      "  Forecast Only: 0.9679\n",
      "  Combined Model: 0.9687\n",
      "\n",
      "Creating 3D visualization of Temperature, Forecast, and Actual Demand...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'accuracy_by_temperature_periodid24 for temp U o bin .csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 351\u001B[0m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;66;03m# Save temperature analysis to CSV\u001B[39;00m\n\u001B[0;32m    350\u001B[0m full_df_with_temp\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mforecast_vs_actual_with_temp_periodid24 for temp u o bin .csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m--> 351\u001B[0m \u001B[43maccuracy_by_temp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreset_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43maccuracy_by_temperature_periodid24 for temp U o bin .csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[38;5;66;03m# Create visualizations\u001B[39;00m\n\u001B[0;32m    354\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mCreating visualizations...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\pythonProject7\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    328\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    329\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39m_format_argument_list(allow_args)),\n\u001B[0;32m    330\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    331\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mfind_stack_level(),\n\u001B[0;32m    332\u001B[0m     )\n\u001B[1;32m--> 333\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\.conda\\envs\\pythonProject7\\lib\\site-packages\\pandas\\core\\generic.py:3967\u001B[0m, in \u001B[0;36mNDFrame.to_csv\u001B[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001B[0m\n\u001B[0;32m   3956\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m, ABCDataFrame) \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mto_frame()\n\u001B[0;32m   3958\u001B[0m formatter \u001B[38;5;241m=\u001B[39m DataFrameFormatter(\n\u001B[0;32m   3959\u001B[0m     frame\u001B[38;5;241m=\u001B[39mdf,\n\u001B[0;32m   3960\u001B[0m     header\u001B[38;5;241m=\u001B[39mheader,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3964\u001B[0m     decimal\u001B[38;5;241m=\u001B[39mdecimal,\n\u001B[0;32m   3965\u001B[0m )\n\u001B[1;32m-> 3967\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameRenderer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformatter\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_csv\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3968\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpath_or_buf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3969\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlineterminator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlineterminator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3970\u001B[0m \u001B[43m    \u001B[49m\u001B[43msep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3972\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3973\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3974\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquoting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquoting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3975\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3976\u001B[0m \u001B[43m    \u001B[49m\u001B[43mindex_label\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_label\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3977\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3978\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunksize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3979\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquotechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3980\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3981\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdoublequote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdoublequote\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3982\u001B[0m \u001B[43m    \u001B[49m\u001B[43mescapechar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mescapechar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3983\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   3984\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\pythonProject7\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001B[0m, in \u001B[0;36mDataFrameRenderer.to_csv\u001B[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001B[0m\n\u001B[0;32m    993\u001B[0m     created_buffer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    995\u001B[0m csv_formatter \u001B[38;5;241m=\u001B[39m CSVFormatter(\n\u001B[0;32m    996\u001B[0m     path_or_buf\u001B[38;5;241m=\u001B[39mpath_or_buf,\n\u001B[0;32m    997\u001B[0m     lineterminator\u001B[38;5;241m=\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1012\u001B[0m     formatter\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfmt,\n\u001B[0;32m   1013\u001B[0m )\n\u001B[1;32m-> 1014\u001B[0m \u001B[43mcsv_formatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1016\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m created_buffer:\n\u001B[0;32m   1017\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(path_or_buf, StringIO)\n",
      "File \u001B[1;32m~\\.conda\\envs\\pythonProject7\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001B[0m, in \u001B[0;36mCSVFormatter.save\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    247\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    248\u001B[0m \u001B[38;5;124;03mCreate the writer & save.\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# apply compression and byte/text conversion\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompression\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m handles:\n\u001B[0;32m    259\u001B[0m     \u001B[38;5;66;03m# Note: self.encoding is irrelevant here\u001B[39;00m\n\u001B[0;32m    260\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwriter \u001B[38;5;241m=\u001B[39m csvlib\u001B[38;5;241m.\u001B[39mwriter(\n\u001B[0;32m    261\u001B[0m         handles\u001B[38;5;241m.\u001B[39mhandle,\n\u001B[0;32m    262\u001B[0m         lineterminator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlineterminator,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    267\u001B[0m         quotechar\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquotechar,\n\u001B[0;32m    268\u001B[0m     )\n\u001B[0;32m    270\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save()\n",
      "File \u001B[1;32m~\\.conda\\envs\\pythonProject7\\lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mPermissionError\u001B[0m: [Errno 13] Permission denied: 'accuracy_by_temperature_periodid24 for temp U o bin .csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# File paths (Hey team please change to your local path 1,2 3)\n",
    "forecast_path = r\"C:\\Users\\waseem\\Desktop\\UNSW\\Graduation Project\\forecastdemand_nsw.csv\" #Change path\n",
    "demand_path = r\"C:\\Users\\waseem\\Desktop\\UNSW\\Graduation Project\\totaldemand_nsw.csv\" # Change path\n",
    "temperature_path = r\"C:\\Users\\waseem\\Desktop\\UNSW\\Graduation Project\\temperature_nsw.csv\" #Change path\n",
    "target_periodid = 24\n",
    "\n",
    "# Load datasets\n",
    "\n",
    "df_forecast = pd.read_csv(forecast_path)\n",
    "df_demand = pd.read_csv(demand_path)\n",
    "df_temperature = pd.read_csv(temperature_path)\n",
    "\n",
    "print(f\"Loaded forecast data: {len(df_forecast)} rows\")\n",
    "print(f\"Loaded demand data: {len(df_demand)} rows\")\n",
    "print(f\"Loaded temperature data: {len(df_temperature)} rows\")\n",
    "\n",
    "# Display samples to check datetime formats\n",
    "print(\"\\nSample forecast datetime:\", df_forecast['DATETIME'].iloc[0] if len(df_forecast) > 0 else \"No data\")\n",
    "print(\"Sample demand datetime:\", df_demand['DATETIME'].iloc[0] if len(df_demand) > 0 else \"No data\")\n",
    "temp_dt_col = 'date_time' if 'date_time' in df_temperature.columns else 'DATETIME'\n",
    "print(f\"Sample temperature {temp_dt_col}:\", df_temperature[temp_dt_col].iloc[0] if len(df_temperature) > 0 else \"No data\")\n",
    "\n",
    "# Filter forecast data for PERIODID 24\n",
    "df_forecast = df_forecast[df_forecast['PERIODID'] == target_periodid]\n",
    "print(f\"Filtered forecast data for PERIODID {target_periodid}: {len(df_forecast)} rows\")\n",
    "\n",
    "# Check if the forecast and demand datetime are already in ISO format (YYYY-MM-DD)\n",
    "forecast_date_format = \"ISO\" if '-' in str(df_forecast['DATETIME'].iloc[0]) else \"Australian\"\n",
    "demand_date_format = \"ISO\" if '-' in str(df_demand['DATETIME'].iloc[0]) else \"Australian\"\n",
    "print(f\"Forecast datetime format appears to be: {forecast_date_format}\")\n",
    "print(f\"Demand datetime format appears to be: {demand_date_format}\")\n",
    "\n",
    "# Parse dates - with appropriate handling for existing formats\n",
    "print(\"Parsing dates...\")\n",
    "\n",
    "# For forecast data\n",
    "if forecast_date_format == \"ISO\":\n",
    "    # Already in ISO format, just parse\n",
    "    df_forecast['DATETIME'] = pd.to_datetime(df_forecast['DATETIME'], errors='coerce')\n",
    "else:\n",
    "    # Australian format, convert to ISO\n",
    "    df_forecast['DATETIME'] = pd.to_datetime(df_forecast['DATETIME'], format=\"%d/%m/%Y %H:%M\", errors='coerce')\n",
    "\n",
    "# For demand data\n",
    "if demand_date_format == \"ISO\":\n",
    "    # Already in ISO format, just parse\n",
    "    df_demand['DATETIME'] = pd.to_datetime(df_demand['DATETIME'], errors='coerce')\n",
    "else:\n",
    "    # Australian format, convert to ISO\n",
    "    df_demand['DATETIME'] = pd.to_datetime(df_demand['DATETIME'], format=\"%d/%m/%Y %H:%M\", errors='coerce')\n",
    "\n",
    "# For temperature data\n",
    "if 'date_time' in df_temperature.columns:\n",
    "    # First convert from Australian format to datetime\n",
    "    df_temperature['date_time'] = pd.to_datetime(df_temperature['date_time'], format=\"%d/%m/%Y %H:%M\", errors='coerce')\n",
    "    # Then create a DATETIME column in the same format as forecast/demand\n",
    "    df_temperature['DATETIME'] = df_temperature['date_time']\n",
    "else:\n",
    "    # Directly parse the DATETIME column\n",
    "    df_temperature['DATETIME'] = pd.to_datetime(df_temperature['DATETIME'], format=\"%d/%m/%Y %H:%M\", errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df_forecast = df_forecast.dropna(subset=['DATETIME'])\n",
    "df_demand = df_demand.dropna(subset=['DATETIME'])\n",
    "df_temperature = df_temperature.dropna(subset=['DATETIME'])\n",
    "\n",
    "# Print sample of  dates to verify format consistency\n",
    "print(\"\\nAfter parsing:\")\n",
    "print(\"Sample forecast datetime:\", df_forecast['DATETIME'].iloc[0] if len(df_forecast) > 0 else \"No data\")\n",
    "print(\"Sample demand datetime:\", df_demand['DATETIME'].iloc[0] if len(df_demand) > 0 else \"No data\")\n",
    "print(\"Sample temperature datetime:\", df_temperature['DATETIME'].iloc[0] if len(df_temperature) > 0 else \"No data\")\n",
    "\n",
    "# Identify temperature column\n",
    "temp_column = 'temperature' if 'temperature' in df_temperature.columns else 'TEMPERATURE'\n",
    "print(f\"Using temperature column: {temp_column}\")\n",
    "\n",
    "# Merge forecast and demand data\n",
    "print(\"Merging forecast with demand data...\")\n",
    "merged_df = pd.merge(\n",
    "    df_forecast,\n",
    "    df_demand[['DATETIME', 'TOTALDEMAND', 'REGIONID']],\n",
    "    on=['DATETIME', 'REGIONID'],\n",
    "    how='inner'\n",
    ")\n",
    "print(f\"Merged forecast and demand: {len(merged_df)} rows\")\n",
    "\n",
    "# If merge failed, debug by examining values more closely\n",
    "if len(merged_df) == 0:\n",
    "    print(\"\\nDEBUG: Merge failed - examining DATETIME values\")\n",
    "\n",
    "    # Convert all to strings in ISO format for comparison\n",
    "    df_forecast['DATETIME_STR'] = df_forecast['DATETIME'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df_demand['DATETIME_STR'] = df_demand['DATETIME'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Print some samples for comparison\n",
    "    print(\"\\nForecast DATETIME samples:\")\n",
    "    print(df_forecast['DATETIME_STR'].head(5).tolist())\n",
    "    print(\"\\nDemand DATETIME samples:\")\n",
    "    print(df_demand['DATETIME_STR'].head(5).tolist())\n",
    "\n",
    "    # Check if there are any exact matches\n",
    "    forecast_set = set(df_forecast['DATETIME_STR'].tolist())\n",
    "    demand_set = set(df_demand['DATETIME_STR'].tolist())\n",
    "    common = forecast_set.intersection(demand_set)\n",
    "    print(f\"\\nNumber of common datetime values: {len(common)}\")\n",
    "\n",
    "    # Try a more flexible merge on date only\n",
    "    print(\"\\nTrying a more flexible merge on date only...\")\n",
    "    df_forecast['DATE'] = df_forecast['DATETIME'].dt.date\n",
    "    df_demand['DATE'] = df_demand['DATETIME'].dt.date\n",
    "\n",
    "    date_merged = pd.merge(\n",
    "        df_forecast,\n",
    "        df_demand[['DATE', 'TOTALDEMAND', 'REGIONID']],\n",
    "        on=['DATE', 'REGIONID'],\n",
    "        how='inner'\n",
    "    )\n",
    "    print(f\"Date-only merge produced {len(date_merged)} rows\")\n",
    "\n",
    "    if len(date_merged) > 0:\n",
    "        merged_df = date_merged\n",
    "        print(\"Using date-only merge for analysis\")\n",
    "    else:\n",
    "        print(\"Analysis cannot continue without matching data\")\n",
    "        exit(1)\n",
    "\n",
    "# Aggregate temperature by hour to handle multiple readings per hour\n",
    "print(\"Aggregating temperature data by hour...\")\n",
    "df_temperature['hour'] = df_temperature['DATETIME'].dt.floor('H')\n",
    "hourly_temp = df_temperature.groupby('hour')[temp_column].mean().reset_index()\n",
    "hourly_temp.rename(columns={temp_column: 'TEMPERATURE'}, inplace=True)\n",
    "\n",
    "# Merge with temperature data\n",
    "print(\"Merging with temperature data...\")\n",
    "# Create an hour column in the merged data for joining data\n",
    "merged_df['hour'] = merged_df['DATETIME'].dt.floor('H')\n",
    "full_df = pd.merge(\n",
    "    merged_df,\n",
    "    hourly_temp,\n",
    "    on='hour',\n",
    "    how='left'\n",
    ")\n",
    "print(f\"Final merged dataset: {len(full_df)} rows\")\n",
    "\n",
    "# If no temperature data was merged, try a different approach\n",
    "if full_df['TEMPERATURE'].isna().all():\n",
    "    print(\"\\nDEBUG: Temperature merge failed - trying date-based match\")\n",
    "\n",
    "    # Create date columns\n",
    "    merged_df['DATE'] = merged_df['DATETIME'].dt.date\n",
    "    df_temperature['DATE'] = df_temperature['DATETIME'].dt.date\n",
    "\n",
    "    # Aggregate temperature by date\n",
    "    daily_temp = df_temperature.groupby('DATE')[temp_column].mean().reset_index()\n",
    "    daily_temp.rename(columns={temp_column: 'TEMPERATURE'}, inplace=True)\n",
    "\n",
    "    # Merge on date\n",
    "    full_df = pd.merge(\n",
    "        merged_df,\n",
    "        daily_temp,\n",
    "        on='DATE',\n",
    "        how='left'\n",
    "    )\n",
    "    print(f\"Date-based temperature merge: {len(full_df)} rows with non-null temperature: {full_df['TEMPERATURE'].notna().sum()}\")\n",
    "\n",
    "# Calculate error metrics\n",
    "full_df['ABS_ERROR'] = abs(full_df['FORECASTDEMAND'] - full_df['TOTALDEMAND'])\n",
    "full_df['PERC_ERROR'] = 100 * full_df['ABS_ERROR'] / full_df['TOTALDEMAND']\n",
    "\n",
    "# Overall accuracy metrics\n",
    "mae = full_df['ABS_ERROR'].mean()\n",
    "mape = full_df['PERC_ERROR'].mean()\n",
    "rmse = np.sqrt((full_df['FORECASTDEMAND'] - full_df['TOTALDEMAND']).pow(2).mean())\n",
    "\n",
    "# Calculate R-squared (coefficient of determination)\n",
    "ss_total = ((full_df['TOTALDEMAND'] - full_df['TOTALDEMAND'].mean()) ** 2).sum()\n",
    "ss_residual = ((full_df['TOTALDEMAND'] - full_df['FORECASTDEMAND']) ** 2).sum()\n",
    "r_squared = 1 - (ss_residual / ss_total)\n",
    "\n",
    "print(\"\\nOverall Forecast Accuracy Metrics for PERIODID 24:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f} MW\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.2f} MW\")\n",
    "print(f\"R-squared (R²): {r_squared:.4f}\")\n",
    "\n",
    "# Save the forecast vs actual data regardless of temperature\n",
    "full_df[['DATETIME', 'REGIONID', 'FORECASTDEMAND', 'TOTALDEMAND', 'ABS_ERROR', 'PERC_ERROR']].to_csv(\n",
    "    'forecast_vs_actual_periodid24.csv', index=False\n",
    ")\n",
    "\n",
    "# Check if we have temperature data before continuing with temperature analysis\n",
    "if full_df['TEMPERATURE'].notna().sum() > 0:\n",
    "    # Analyze impact of temperature on forecast accuracy\n",
    "    print(\"\\nAnalyzing temperature impact on forecast accuracy...\")\n",
    "\n",
    "    # Remove rows with missing temperature values\n",
    "    full_df_with_temp = full_df.dropna(subset=['TEMPERATURE'])\n",
    "    print(f\"Rows with temperature data: {len(full_df_with_temp)} out of {len(full_df)} total rows\")\n",
    "\n",
    "    # Create temperature bins with specific temperature ranges as requested\n",
    "    temp_bins = [-10, 0, 5, 10, 15, 20, 25, 30, 35, 40, 50]\n",
    "    temp_labels = ['<= 0', '0-5', '5-10', '10-15', '15-20', '20-25', '25-30', '30-35', '35-40', '> 40']\n",
    "\n",
    "    # Create the temperature ranges with specified bins\n",
    "    full_df_with_temp['TEMP_RANGE'] = pd.cut(\n",
    "        full_df_with_temp['TEMPERATURE'],\n",
    "        bins=temp_bins,\n",
    "        labels=temp_labels,\n",
    "        include_lowest=True\n",
    "    )\n",
    "\n",
    "    # Print information about the created temperature ranges\n",
    "    print(f\"\\nUsing specified temperature ranges:\")\n",
    "    temp_range_counts = full_df_with_temp['TEMP_RANGE'].value_counts().sort_index()\n",
    "    for range_name, count in temp_range_counts.items():\n",
    "        print(f\"  {range_name}: {count} samples\")\n",
    "\n",
    "    # Function to calculate R-squared for a group\n",
    "    def calculate_r_squared(group):\n",
    "        if len(group) < 3:\n",
    "            return np.nan\n",
    "        ss_total = ((group['TOTALDEMAND'] - group['TOTALDEMAND'].mean()) ** 2).sum()\n",
    "        if ss_total == 0:\n",
    "            return np.nan\n",
    "        ss_residual = ((group['TOTALDEMAND'] - group['FORECASTDEMAND']) ** 2).sum()\n",
    "        return 1 - (ss_residual / ss_total)\n",
    "\n",
    "    # Group by temperature range and calculate accuracy metrics\n",
    "    accuracy_by_temp = full_df_with_temp.groupby('TEMP_RANGE').agg({\n",
    "        'ABS_ERROR': 'mean',\n",
    "        'PERC_ERROR': 'mean',\n",
    "        'TEMPERATURE': 'count'\n",
    "    }).rename(columns={'ABS_ERROR': 'MAE', 'PERC_ERROR': 'MAPE', 'TEMPERATURE': 'Count'})\n",
    "\n",
    "    # Calculate R-squared for each temperature range\n",
    "    r_squared_by_temp = full_df_with_temp.groupby('TEMP_RANGE').apply(calculate_r_squared)\n",
    "    accuracy_by_temp['R-squared'] = r_squared_by_temp\n",
    "\n",
    "    print(\"\\nForecast Accuracy by Temperature Range:\")\n",
    "    display(accuracy_by_temp)\n",
    "\n",
    "    # Non-linear (polynomial) model with both temperature and forecast as predictors\n",
    "    print(\"\\nFitting nonlinear model with temperature and forecast as predictors...\")\n",
    "\n",
    "    # Create polynomial features for temperature (to capture U-shape)\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import r2_score\n",
    "\n",
    "    # Prepare the data\n",
    "    X = full_df_with_temp[['TEMPERATURE', 'FORECASTDEMAND']]\n",
    "    y = full_df_with_temp['TOTALDEMAND']\n",
    "\n",
    "    # Create polynomial features for temperature (degree 2 for U-shape)\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_temp_poly = poly.fit_transform(full_df_with_temp[['TEMPERATURE']])\n",
    "\n",
    "    # Combine polynomial temperature features with forecast\n",
    "    X_combined = np.column_stack((X_temp_poly, full_df_with_temp['FORECASTDEMAND']))\n",
    "\n",
    "    # Fit the model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_combined, y)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_combined)\n",
    "\n",
    "    # Calculate R-squared\n",
    "    r2_combined = r2_score(y, y_pred)\n",
    "\n",
    "    print(f\"\\nNonlinear Model Results (Polynomial Temperature + Forecast):\")\n",
    "    print(f\"R-squared: {r2_combined:.4f}\")\n",
    "    print(f\"Coefficients:\")\n",
    "\n",
    "    # Get feature names\n",
    "    feature_names = [f'Temperature', f'Temperature²', 'Forecast']\n",
    "    for name, coef in zip(feature_names, model.coef_):\n",
    "        print(f\"  {name}: {coef:.6f}\")\n",
    "    print(f\"  Intercept: {model.intercept_:.6f}\")\n",
    "\n",
    "    # Individual R-squared values for comparison\n",
    "    # 1. Temperature only (linear)\n",
    "    model_temp_linear = LinearRegression()\n",
    "    model_temp_linear.fit(full_df_with_temp[['TEMPERATURE']], y)\n",
    "    r2_temp_linear = r2_score(y, model_temp_linear.predict(full_df_with_temp[['TEMPERATURE']]))\n",
    "\n",
    "    # 2. Temperature only (polynomial)\n",
    "    model_temp_poly = LinearRegression()\n",
    "    model_temp_poly.fit(X_temp_poly, y)\n",
    "    r2_temp_poly = r2_score(y, model_temp_poly.predict(X_temp_poly))\n",
    "\n",
    "    # 3. Forecast only\n",
    "    model_forecast = LinearRegression()\n",
    "    model_forecast.fit(full_df_with_temp[['FORECASTDEMAND']], y)\n",
    "    r2_forecast = r2_score(y, model_forecast.predict(full_df_with_temp[['FORECASTDEMAND']]))\n",
    "\n",
    "    print(\"\\nR-squared Comparison:\")\n",
    "    print(f\"  Temperature Only (Linear): {r2_temp_linear:.4f}\")\n",
    "    print(f\"  Temperature Only (Polynomial): {r2_temp_poly:.4f}\")\n",
    "    print(f\"  Forecast Only: {r2_forecast:.4f}\")\n",
    "    print(f\"  Combined Model: {r2_combined:.4f}\")\n",
    "\n",
    "    # Visualize the relationship between temperature, forecast and actual demand\n",
    "    print(\"\\nCreating 3D visualization of Temperature, Forecast, and Actual Demand...\")\n",
    "\n",
    "    # If we have many data points, sample to make the plot clearer\n",
    "    plot_data = full_df_with_temp\n",
    "    if len(full_df_with_temp) > 1000:\n",
    "        plot_data = full_df_with_temp.sample(1000, random_state=42)\n",
    "\n",
    "    # Create a 3D scatter plot\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    scatter = ax.scatter(\n",
    "        plot_data['TEMPERATURE'],\n",
    "        plot_data['FORECASTDEMAND'],\n",
    "        plot_data['TOTALDEMAND'],\n",
    "        c=plot_data['TOTALDEMAND'],\n",
    "        cmap='viridis',\n",
    "        s=50,\n",
    "        alpha=0.6\n",
    "    )\n",
    "\n",
    "    ax.set_xlabel('Temperature (°C)')\n",
    "    ax.set_ylabel('Forecast Demand (MW)')\n",
    "    ax.set_zlabel('Actual Demand (MW)')\n",
    "    ax.set_title(f'3D Relationship: Temperature, Forecast and Actual Demand (PERIODID {target_periodid})')\n",
    "\n",
    "    # Add a color bar\n",
    "    cbar = fig.colorbar(scatter, ax=ax, label='Actual Demand (MW)')\n",
    "\n",
    "    # Save the 3D plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('3d_relationship_temp_forecast_actual for temp U obin.png')\n",
    "    plt.close()\n",
    "\n",
    "    # Save temperature analysis to CSV\n",
    "    full_df_with_temp.to_csv('forecast_vs_actual_with_temp_periodid24 for temp u o bin .csv', index=False)\n",
    "    accuracy_by_temp.reset_index().to_csv('accuracy_by_temperature_periodid24 for temp U o bin .csv', index=False)\n",
    "\n",
    "    # Create visualizations\n",
    "    print(\"\\nCreating visualizations...\")\n",
    "\n",
    "    # 1. Scatter plot of Forecasted vs Actual Demand colored by temperature\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(\n",
    "        full_df_with_temp['TOTALDEMAND'],\n",
    "        full_df_with_temp['FORECASTDEMAND'],\n",
    "        c=full_df_with_temp['TEMPERATURE'],\n",
    "        cmap='coolwarm',\n",
    "        alpha=0.7\n",
    "    )\n",
    "    plt.colorbar(scatter, label='Temperature (°C)')\n",
    "    plt.plot([full_df_with_temp['TOTALDEMAND'].min(), full_df_with_temp['TOTALDEMAND'].max()],\n",
    "             [full_df_with_temp['TOTALDEMAND'].min(), full_df_with_temp['TOTALDEMAND'].max()],\n",
    "             'k--', label='Perfect Forecast')\n",
    "    plt.title(f'Forecast vs Actual Demand (PERIODID {target_periodid})')\n",
    "    plt.xlabel('Actual Demand (MW)')\n",
    "    plt.ylabel('Forecasted Demand (MW)')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('forecast_vs_actual_periodid24 fortemp U o bin .png')\n",
    "    plt.close()\n",
    "\n",
    "    # 2. Error distribution by temperature range\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Create boxplot manually to ensure correct ordering\n",
    "    ranges = full_df_with_temp['TEMP_RANGE'].unique().tolist()\n",
    "    ranges.sort()  # Sort the ranges\n",
    "\n",
    "    # Collect data for each range\n",
    "    box_data = [full_df_with_temp[full_df_with_temp['TEMP_RANGE'] == temp_range]['PERC_ERROR'].values\n",
    "                for temp_range in ranges]\n",
    "\n",
    "    # Create the boxplot\n",
    "    plt.boxplot(box_data, labels=ranges)\n",
    "\n",
    "    plt.title(f'Forecast Error Distribution by Temperature Range (PERIODID {target_periodid})')\n",
    "    plt.xlabel('Temperature Range')\n",
    "    plt.ylabel('Percentage Error (%)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('error_by_temperature_periodid24 fortemp U o bin .png')\n",
    "    plt.close()\n",
    "\n",
    "    # 3. Correlation between temperature and forecast error\n",
    "    if len(full_df_with_temp) > 10:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(full_df_with_temp['TEMPERATURE'], full_df_with_temp['PERC_ERROR'], alpha=0.5)\n",
    "        plt.title(f'Temperature vs Forecast Error (PERIODID {target_periodid})')\n",
    "        plt.xlabel('Temperature (°C)')\n",
    "        plt.ylabel('Percentage Error (%)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "\n",
    "        # Add trend line\n",
    "        if len(full_df_with_temp) > 2:  # Need at least 3 points for a trend line\n",
    "            z = np.polyfit(full_df_with_temp['TEMPERATURE'], full_df_with_temp['PERC_ERROR'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            temp_range = np.linspace(full_df_with_temp['TEMPERATURE'].min(), full_df_with_temp['TEMPERATURE'].max(), 100)\n",
    "            plt.plot(temp_range, p(temp_range), \"r--\", linewidth=2)\n",
    "\n",
    "            corr = full_df_with_temp['TEMPERATURE'].corr(full_df_with_temp['PERC_ERROR'])\n",
    "            plt.annotate(f'Correlation: {corr:.4f}',\n",
    "                        xy=(0.05, 0.95),\n",
    "                        xycoords='axes fraction',\n",
    "                        bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('temperature_vs_error_periodid24 fortemp U Obin.png')\n",
    "        plt.close()\n",
    "\n",
    "    # 4. R-squared by temperature range\n",
    "    if 'R-squared' in accuracy_by_temp.columns and not accuracy_by_temp['R-squared'].isna().all():\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        # Convert index to list for proper ordering in the plot\n",
    "        ranges = accuracy_by_temp.index.tolist()\n",
    "\n",
    "        # Plot the bar chart\n",
    "        plt.bar(range(len(ranges)), accuracy_by_temp['R-squared'])\n",
    "\n",
    "        # Set the tick positions and labels\n",
    "        plt.xticks(range(len(ranges)), ranges, rotation=45)\n",
    "\n",
    "        plt.title(f'R-squared by Temperature Range (PERIODID {target_periodid})')\n",
    "        plt.xlabel('Temperature Range')\n",
    "        plt.ylabel('R-squared (R²)')\n",
    "        plt.ylim(0, 1)  # R-squared is typically between 0 and 1\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('r_squared_by_temperature_periodid24 fortemp U Obin.png')\n",
    "        plt.close()\n",
    "else:\n",
    "    print(\"\\nNo temperature data was successfully matched with forecast/demand data.\")\n",
    "    print(\"Skipping temperature-related analysis.\")\n",
    "\n",
    "\n",
    "# Get a sample period for better visualization (most recent 14 days)\n",
    "full_df_sorted = full_df.sort_values('DATETIME')\n",
    "sample_period = full_df_sorted.tail(min(24*14, len(full_df_sorted)))\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(sample_period['DATETIME'], sample_period['TOTALDEMAND'], 'b-', label='Actual Demand')\n",
    "plt.plot(sample_period['DATETIME'], sample_period['FORECASTDEMAND'], 'r--', label='Forecast Demand')\n",
    "plt.title(f'Forecast vs Actual Demand Over Time (PERIODID {target_periodid})')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Demand (MW)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('time_series_forecast_actual_periodid24 fortemp U Obin.png')\n",
    "plt.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
